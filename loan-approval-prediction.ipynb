{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loan Approval Prediction Using Machine Learning\nIn this Notebook, we are going to solve the Loan Approval Prediction. This is a classification problem in which we need to classify whether the loan will be approved or not. Classification refers to a predictive modeling problem where a class label is predicted for a given example of input data. A few examples of classification problems are Spam Email detection, Cancer detection, Sentiment Analysis, etc.","metadata":{}},{"cell_type":"markdown","source":"# Understanding the Problem Statement \nA loan is a bank's main source of revenue. The profits earned through loans account for most of the bank's profits. Even though the bank accepts the loan following a lengthy verification and testimony process, there is no guarantee that the chosen candidate is the right one. When done manually, this operation takes a long time. We can predict whether a given hopeful is safe or not, and the entire testimonial process is automated using machine literacy. Loan Prognostic is beneficial to both bank retainers and hopefuls. \n\nThe Bank wants to automate the loan eligibility process (real-time) based on customer detail provided while filling out online application forms. These details are Gender, Marital Status, Education, number of Dependents, Income, Loan Amount, Credit History, and others.\n\nTo automate this process, they have provided a dataset to identify the customer segments that are eligible for loan amounts so that they can specifically target these customers.\n\nAs mentioned above this is a Binary Classification problem in which we need to predict our Target label which is “Loan Status”.\n\nLoan status can have two values: Yes or No.\n\n* Yes: if the loan is approved\n* No: if the loan is not approved\n\nSo using the training dataset we will train our model and try to predict our target column that is “Loan Status” on the test dataset.\n","metadata":{}},{"cell_type":"markdown","source":"# Load Essential Python Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.479704Z","iopub.execute_input":"2022-05-15T13:22:58.480015Z","iopub.status.idle":"2022-05-15T13:22:58.488518Z","shell.execute_reply.started":"2022-05-15T13:22:58.479983Z","shell.execute_reply":"2022-05-15T13:22:58.487606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Training/ Test Dataset","metadata":{}},{"cell_type":"code","source":"train = \"../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv\"\ntrain = pd.read_csv(train)\ntest = \"../input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv\"\ntest = pd.read_csv(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.507339Z","iopub.execute_input":"2022-05-15T13:22:58.507912Z","iopub.status.idle":"2022-05-15T13:22:58.535352Z","shell.execute_reply.started":"2022-05-15T13:22:58.507875Z","shell.execute_reply":"2022-05-15T13:22:58.534616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# About the dataset ","metadata":{}},{"cell_type":"code","source":"#Size of Train Data\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.536989Z","iopub.execute_input":"2022-05-15T13:22:58.537377Z","iopub.status.idle":"2022-05-15T13:22:58.54213Z","shell.execute_reply.started":"2022-05-15T13:22:58.537337Z","shell.execute_reply":"2022-05-15T13:22:58.541365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we have 614 rows and 13 columns in our training dataset.","metadata":{}},{"cell_type":"code","source":"#Size of Test Data\ntest.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.54322Z","iopub.execute_input":"2022-05-15T13:22:58.54357Z","iopub.status.idle":"2022-05-15T13:22:58.557234Z","shell.execute_reply.started":"2022-05-15T13:22:58.543541Z","shell.execute_reply":"2022-05-15T13:22:58.556216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In test data, we have 367 rows and 12 columns because the target column is not included in the test data.","metadata":{}},{"cell_type":"code","source":"#Information about train Dataset\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.559075Z","iopub.execute_input":"2022-05-15T13:22:58.560087Z","iopub.status.idle":"2022-05-15T13:22:58.577848Z","shell.execute_reply.started":"2022-05-15T13:22:58.560027Z","shell.execute_reply":"2022-05-15T13:22:58.576463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First look at the Dataset\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.579941Z","iopub.execute_input":"2022-05-15T13:22:58.580196Z","iopub.status.idle":"2022-05-15T13:22:58.598946Z","shell.execute_reply.started":"2022-05-15T13:22:58.580166Z","shell.execute_reply":"2022-05-15T13:22:58.598181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Categorical Columns: \n1. Gender (Male/Female), \n2. Married (Yes/No), \n3. Number of dependents (Possible values:0,1,2,3+), \n4. Education (Graduate / Not Graduate), \n5. Self-Employed (No/Yes), \n6. credit history(Yes/No), \n7. Property Area (Rural/Semi-Urban/Urban) and \n8. Loan Status (Y/N)(i. e. Target variable)\n\nNumerical Columns: \n1. Loan ID, \n2. Applicant Income, \n3. Co-applicant Income, \n4. Loan Amount, and \n5. Loan amount term","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Concatenating the train and test data for data preprocessing:\ndata = pd.concat([train,test])","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.600057Z","iopub.execute_input":"2022-05-15T13:22:58.600484Z","iopub.status.idle":"2022-05-15T13:22:58.620199Z","shell.execute_reply.started":"2022-05-15T13:22:58.600448Z","shell.execute_reply":"2022-05-15T13:22:58.619388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the unwanted column:\ndata.drop('Loan_ID', inplace=True, axis='columns')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.621338Z","iopub.execute_input":"2022-05-15T13:22:58.621713Z","iopub.status.idle":"2022-05-15T13:22:58.631265Z","shell.execute_reply.started":"2022-05-15T13:22:58.621671Z","shell.execute_reply":"2022-05-15T13:22:58.63053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify missing values:\ndata.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.632391Z","iopub.execute_input":"2022-05-15T13:22:58.632743Z","iopub.status.idle":"2022-05-15T13:22:58.647646Z","shell.execute_reply.started":"2022-05-15T13:22:58.632712Z","shell.execute_reply":"2022-05-15T13:22:58.646538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values:\ndata['Gender'].fillna(data['Gender'].mode()[0], inplace = True)\ndata['Married'].fillna(data['Married'].mode()[0], inplace = True)\ndata['Dependents'].fillna(data['Dependents'].mode()[0], inplace = True)\ndata['Self_Employed'].fillna(data['Self_Employed'].mode()[0], inplace = True)\ndata['Credit_History'].fillna(data['Credit_History'].mode()[0], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.649131Z","iopub.execute_input":"2022-05-15T13:22:58.649897Z","iopub.status.idle":"2022-05-15T13:22:58.664375Z","shell.execute_reply.started":"2022-05-15T13:22:58.64986Z","shell.execute_reply":"2022-05-15T13:22:58.663574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next, we will be using Iterative imputer for filling missing values of LoanAmount and Loan_Amount_Term\ndata1 = data.loc[:,['LoanAmount','Loan_Amount_Term']]\n\nfrom sklearn.ensemble import RandomForestRegressor\n#Running the imputer with a Random Forest Estimator\nimp = IterativeImputer(RandomForestRegressor(), max_iter=1000, random_state=0)\ndata1 = pd.DataFrame(imp.fit_transform(data1), columns=data1.columns)\n\ndata['LoanAmount'] = data1['LoanAmount']\ndata['Loan_Amount_Term'] = data1['Loan_Amount_Term']","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:22:58.667709Z","iopub.execute_input":"2022-05-15T13:22:58.668372Z","iopub.status.idle":"2022-05-15T13:29:25.386217Z","shell.execute_reply.started":"2022-05-15T13:22:58.668322Z","shell.execute_reply":"2022-05-15T13:29:25.385153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# So now as we have imputed all the missing values we go on to mapping the categorical variables with the integers.\ndata['Gender'] = data['Gender'].map({'Male':0,'Female':1}).astype(int)\ndata['Married'] = data['Married'].map({'No':0,'Yes':1}).astype(int)\ndata['Education'] = data['Education'].map({'Not Graduate':0,'Graduate':1}).astype(int)\ndata['Self_Employed'] = data['Self_Employed'].map({'No':0,'Yes':1}).astype(int)\ndata['Credit_History'] = data['Credit_History'].astype(int)    ","metadata":{"code_folding":[],"execution":{"iopub.status.busy":"2022-05-15T13:29:25.389453Z","iopub.execute_input":"2022-05-15T13:29:25.389675Z","iopub.status.idle":"2022-05-15T13:29:25.403544Z","shell.execute_reply.started":"2022-05-15T13:29:25.389648Z","shell.execute_reply":"2022-05-15T13:29:25.402524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Property_Area'] = data['Property_Area'].map({'Urban':0,'Rural':1, 'Semiurban':2}).astype(int)\ndata['Dependents'] = data['Dependents'].map({'0':0, '1':1, '2':2, '3+':3})","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:25.405147Z","iopub.execute_input":"2022-05-15T13:29:25.405405Z","iopub.status.idle":"2022-05-15T13:29:25.420918Z","shell.execute_reply.started":"2022-05-15T13:29:25.405375Z","shell.execute_reply":"2022-05-15T13:29:25.420029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We map the values so that we can input the train data into the model as the model does not accept any string values.","metadata":{}},{"cell_type":"code","source":"#creating a new feature\ndata['Total_Income'] = data['ApplicantIncome'] + data['CoapplicantIncome']\ndata.drop(['ApplicantIncome', 'CoapplicantIncome'], axis='columns', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:25.422142Z","iopub.execute_input":"2022-05-15T13:29:25.42238Z","iopub.status.idle":"2022-05-15T13:29:25.436404Z","shell.execute_reply.started":"2022-05-15T13:29:25.422352Z","shell.execute_reply":"2022-05-15T13:29:25.435421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA) ","metadata":{}},{"cell_type":"code","source":"# Splitting the data to new_train and new_test so that we can perform EDA.\nnew_train = data.iloc[:614]\nnew_test = data.iloc[614:]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:25.437665Z","iopub.execute_input":"2022-05-15T13:29:25.438002Z","iopub.status.idle":"2022-05-15T13:29:25.45093Z","shell.execute_reply.started":"2022-05-15T13:29:25.437973Z","shell.execute_reply":"2022-05-15T13:29:25.450183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping ‘N’ to 0 and ‘Y’ to 1\nnew_train['Loan_Status'] = new_train['Loan_Status'].map({'N':0,'Y':1}).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:25.452213Z","iopub.execute_input":"2022-05-15T13:29:25.452568Z","iopub.status.idle":"2022-05-15T13:29:25.466322Z","shell.execute_reply.started":"2022-05-15T13:29:25.45254Z","shell.execute_reply":"2022-05-15T13:29:25.465484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Univariate Analysis:\nfig,ax = plt.subplots(2,4,figsize=(16,10))\nsns.countplot(x='Loan_Status', data = new_train, ax=ax[0][0])\nsns.countplot(x='Gender', data = new_train, ax=ax[0][1])\nsns.countplot(x='Married', data = new_train, ax=ax[0][2])\nsns.countplot(x='Education', data = new_train, ax=ax[0][3])\nsns.countplot(x='Self_Employed', data = new_train, ax=ax[1][0])\nsns.countplot(x='Property_Area', data = new_train, ax=ax[1][1])\nsns.countplot(x='Credit_History', data = new_train, ax=ax[1][2])\nsns.countplot(x='Dependents', data = new_train, ax=ax[1][3])","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:25.467539Z","iopub.execute_input":"2022-05-15T13:29:25.467857Z","iopub.status.idle":"2022-05-15T13:29:26.200596Z","shell.execute_reply.started":"2022-05-15T13:29:25.46783Z","shell.execute_reply":"2022-05-15T13:29:26.199485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Univariate Analysis Observations:\n\n1. More Loans are approved Vs Rejected\n2. Count of Male applicants is more than Female\n3. Count of Married applicant is more than Non-married\n4. Count of graduate is more than non-Graduate\n5. Count of self-employed is less than that of Non-Self-employed\n6. Maximum properties are located in Semiurban areas\n7. Credit History is present for many applicants\n8. The count of applicants with several dependents=0 is maximum.","metadata":{}},{"cell_type":"code","source":"# Bivariate Analysis\nsns.boxplot(x='Loan_Status', y='Total_Income', data=new_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:26.202457Z","iopub.execute_input":"2022-05-15T13:29:26.202763Z","iopub.status.idle":"2022-05-15T13:29:26.350123Z","shell.execute_reply.started":"2022-05-15T13:29:26.202721Z","shell.execute_reply":"2022-05-15T13:29:26.349336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mean Total_Income of 0 and 1 are almost the same (o: no,1: Yes)","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='Gender', y='LoanAmount', data=new_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:26.351629Z","iopub.execute_input":"2022-05-15T13:29:26.35226Z","iopub.status.idle":"2022-05-15T13:29:26.488759Z","shell.execute_reply.started":"2022-05-15T13:29:26.352214Z","shell.execute_reply":"2022-05-15T13:29:26.487755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The mean value of Loan Amount applied by males (0) is slightly higher than Females(1).","metadata":{}},{"cell_type":"code","source":"# Correlation matrix\nplt.figure(figsize = (10,10))\ncorrelation_matrix = new_train.corr()\nsns.heatmap(correlation_matrix, annot=True, cmap='RdYlGn')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:26.490245Z","iopub.execute_input":"2022-05-15T13:29:26.49127Z","iopub.status.idle":"2022-05-15T13:29:27.260325Z","shell.execute_reply.started":"2022-05-15T13:29:26.491222Z","shell.execute_reply":"2022-05-15T13:29:27.259067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Machine Learning Model","metadata":{}},{"cell_type":"code","source":"# Creating X (input variables) and Y (Target Variable) from the new_train data.\nx = new_train.drop('Loan_Status', axis='columns')\ny = new_train['Loan_Status']","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:29:27.261947Z","iopub.execute_input":"2022-05-15T13:29:27.262262Z","iopub.status.idle":"2022-05-15T13:29:27.270666Z","shell.execute_reply.started":"2022-05-15T13:29:27.262221Z","shell.execute_reply":"2022-05-15T13:29:27.269802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using train test split on the training data for validation\nX_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=3)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:19.702727Z","iopub.execute_input":"2022-05-15T13:33:19.702997Z","iopub.status.idle":"2022-05-15T13:33:19.710738Z","shell.execute_reply.started":"2022-05-15T13:33:19.702969Z","shell.execute_reply":"2022-05-15T13:33:19.709758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have a (70:30) split on the training data.","metadata":{}},{"cell_type":"markdown","source":"## Decison Tree","metadata":{}},{"cell_type":"code","source":"#Building the model using DecisonTree\nfrom sklearn.tree import DecisionTreeClassifier\n\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:31:48.601754Z","iopub.execute_input":"2022-05-15T13:31:48.602411Z","iopub.status.idle":"2022-05-15T13:31:48.616045Z","shell.execute_reply.started":"2022-05-15T13:31:48.602346Z","shell.execute_reply":"2022-05-15T13:31:48.615003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we will be making the predictions on the testing data directly as it is of more importance.\nfrom sklearn import metrics\n\n# Getting the accuracy score for Decision Tree\ndtree_pred = dtree.predict(X_test)\nprint(\"Accuracy Score =\", format(metrics.accuracy_score(y_test,dtree_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:31:48.628189Z","iopub.execute_input":"2022-05-15T13:31:48.629192Z","iopub.status.idle":"2022-05-15T13:31:48.640858Z","shell.execute_reply.started":"2022-05-15T13:31:48.629141Z","shell.execute_reply":"2022-05-15T13:31:48.639476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report and confusion matrix of the decision tree model\nprint(confusion_matrix(y_test, dtree_pred))\nprint(classification_report(y_test,dtree_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:31:48.642474Z","iopub.execute_input":"2022-05-15T13:31:48.644722Z","iopub.status.idle":"2022-05-15T13:31:48.661055Z","shell.execute_reply.started":"2022-05-15T13:31:48.644671Z","shell.execute_reply":"2022-05-15T13:31:48.659914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"#Building the model using RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\n\n# Getting the accuracy score for Random Forest\nrfc_pred = rfc.predict(X_test)\nprint(\"Accuracy_Score =\", format(metrics.accuracy_score(y_test, rfc_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:31:48.721907Z","iopub.execute_input":"2022-05-15T13:31:48.724168Z","iopub.status.idle":"2022-05-15T13:31:49.2115Z","shell.execute_reply.started":"2022-05-15T13:31:48.724126Z","shell.execute_reply":"2022-05-15T13:31:49.210772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report and confusion matrix of the Random Forest model\nprint(confusion_matrix(y_test, rfc_pred))\nprint(classification_report(y_test,rfc_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:31:49.212823Z","iopub.execute_input":"2022-05-15T13:31:49.213513Z","iopub.status.idle":"2022-05-15T13:31:49.226038Z","shell.execute_reply.started":"2022-05-15T13:31:49.213469Z","shell.execute_reply":"2022-05-15T13:31:49.225029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"#Building the model using LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(max_iter=1000)\nlogreg.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:26.461229Z","iopub.execute_input":"2022-05-15T13:33:26.462242Z","iopub.status.idle":"2022-05-15T13:33:26.517167Z","shell.execute_reply.started":"2022-05-15T13:33:26.462183Z","shell.execute_reply":"2022-05-15T13:33:26.516102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg.predict(X_test)\n\n# Getting the accuracy score for Logistic Regression\nlogreg_pred = logreg.predict(X_test)\nprint(\"Accuracy_Score =\", format(metrics.accuracy_score(y_test, logreg_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:26.599757Z","iopub.execute_input":"2022-05-15T13:33:26.600551Z","iopub.status.idle":"2022-05-15T13:33:26.613453Z","shell.execute_reply.started":"2022-05-15T13:33:26.600504Z","shell.execute_reply":"2022-05-15T13:33:26.612137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report and confusion matrix of the SVM\nprint(confusion_matrix(y_test,logreg_pred ))\nprint(classification_report(y_test,logreg_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:26.760038Z","iopub.execute_input":"2022-05-15T13:33:26.760396Z","iopub.status.idle":"2022-05-15T13:33:26.772262Z","shell.execute_reply.started":"2022-05-15T13:33:26.760362Z","shell.execute_reply":"2022-05-15T13:33:26.771562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the ROC Curve","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:51:53.678629Z","iopub.execute_input":"2022-05-15T08:51:53.67885Z","iopub.status.idle":"2022-05-15T08:51:53.683294Z","shell.execute_reply.started":"2022-05-15T08:51:53.678828Z","shell.execute_reply":"2022-05-15T08:51:53.682048Z"}}},{"cell_type":"code","source":"#Get predictions of Random Forest and Logistic Regression models in the form of probability values\ny_lg_prob = logreg.predict_proba(X_test)[:,1]\ny_rfc_prob = rfc.predict_proba(X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:27.042069Z","iopub.execute_input":"2022-05-15T13:33:27.042885Z","iopub.status.idle":"2022-05-15T13:33:27.092095Z","shell.execute_reply.started":"2022-05-15T13:33:27.042832Z","shell.execute_reply":"2022-05-15T13:33:27.090947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For Logistic Regression\nfpr, tpr, _ = metrics.roc_curve(y_test,y_lg_prob)\nauc = metrics.roc_auc_score(y_test, y_lg_prob)\n\n#For Random Forest\nfpr1, tpr1, _1 = metrics.roc_curve(y_test,y_rfc_prob)\nauc1 = metrics.roc_auc_score(y_test, y_rfc_prob)\n\n#create ROC curve\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Random', alpha=.8)\nplt.plot(fpr,tpr,label=\"LR AUC = \"+str(round(auc,3)))\nplt.plot(fpr1,tpr1,label=\"RFC AUC = \"+str(round(auc1,3)))\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc=4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:27.200945Z","iopub.execute_input":"2022-05-15T13:33:27.20128Z","iopub.status.idle":"2022-05-15T13:33:27.440727Z","shell.execute_reply.started":"2022-05-15T13:33:27.201247Z","shell.execute_reply":"2022-05-15T13:33:27.440009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Importance","metadata":{}},{"cell_type":"markdown","source":"Knowing about the feature importance is quite necessary as it shows that how much weightage each feature provides in the model building phase.","metadata":{}},{"cell_type":"code","source":"# Getting feature importances for Random Forest model\n(pd.Series(rfc.feature_importances_, index=X_train.columns).plot(kind='barh'))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:31:49.620435Z","iopub.execute_input":"2022-05-15T13:31:49.621323Z","iopub.status.idle":"2022-05-15T13:31:50.076314Z","shell.execute_reply.started":"2022-05-15T13:31:49.621273Z","shell.execute_reply":"2022-05-15T13:31:50.075336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Conclusion from Model Building","metadata":{}},{"cell_type":"markdown","source":"Therefore, Random Forest and Logistic Regression are the best model for this prediction since their accuracy_score lies between 0.83 to 0.85.\nAfter using all these customer records, we are able to build a machine learning model to accurately predict whether or not the customers in the dataset would get loan approved or not along with that we were able to draw some insights from the data via data analysis and visualization.","metadata":{}}]}